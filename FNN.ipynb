{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZipWa86hUhS"
      },
      "source": [
        "# Feed Forward Neural Network\n",
        "\n",
        "*   Input data shape (12906, 658) encoded with corresponding integers.\n",
        "\n",
        "*   The training accuracy with 60 epochs is about 94.4%.\n",
        "\n",
        "*   The final Kaggle score is 94.341%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmbv-gkFU_Lp"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "smAePK6nVjKV",
        "outputId": "3ad31806-20f5-4846-a8c8-d739b02d14ca"
      },
      "source": [
        "## adjust the length of DNA sequence with 658\n",
        "## remove the uncorrect characters 'K','M', 'N', 'R', 'S', 'W', 'Y'\n",
        "df = pd.read_csv (r'/content/train_features.csv')\n",
        "def equal_length(seq):\n",
        "    seq2 = seq.ljust(1058, '-') \n",
        "    fir = seq2[0:658]\n",
        "    remove_characters = ['K','M', 'N', 'R', 'S', 'W', 'Y']\n",
        "    for character in remove_characters:\n",
        "        fir = fir.replace(character, \"-\")\n",
        "    return fir\n",
        "dna = df.dna.apply(equal_length)\n",
        "## Example for arbitrary DNA sequence\n",
        "dna[3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AACATTATATTTTATTTTTGGTGCATGAGCTGGAATAGTAGGAACTTCATTAAGTATGCTAATTCGAGCTGAATTAGGAAACCCAGGTGCATTAATTGGAGATGACCAAATTTATAATGTTATTGTTACTGCACATGCATTTATTATGATTTTTTTTATAGTTATACCTATTATAATTGGAGGATTTGGAAATTGATTAGTTCCTTTAATATTAGGAGCCCCAGATATAGCTTTTCCTCGAATAAATAATATAAGTTTTTGATTACTTCCTCCTTCATTAACGCTCCTCTTAATAAGAAGTCTAGTG---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2FkaLpyYS04",
        "outputId": "11099e5a-bd1f-47c6-ac56-7528017e3514"
      },
      "source": [
        "## Transfer character to int\n",
        "from numpy import argmax\n",
        "def num_encoder(seq):\n",
        "  alphabet = 'ACGT-'\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "  to_array = [char_to_int[char] for char in seq]\n",
        "  return(np.array(to_array).reshape((658)))\n",
        "\n",
        "dna_code = np.array(dna.apply(num_encoder).to_list())\n",
        "## Example\n",
        "dna_code[3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 2, 3,\n",
              "       2, 1, 0, 3, 2, 0, 2, 1, 3, 2, 2, 0, 0, 3, 0, 2, 3, 0, 2, 2, 0, 0,\n",
              "       1, 3, 3, 1, 0, 3, 3, 0, 0, 2, 3, 0, 3, 2, 1, 3, 0, 0, 3, 3, 1, 2,\n",
              "       0, 2, 1, 3, 2, 0, 0, 3, 3, 0, 2, 2, 0, 0, 0, 1, 1, 1, 0, 2, 2, 3,\n",
              "       2, 1, 0, 3, 3, 0, 0, 3, 3, 2, 2, 0, 2, 0, 3, 2, 0, 1, 1, 0, 0, 0,\n",
              "       3, 3, 3, 0, 3, 0, 0, 3, 2, 3, 3, 0, 3, 3, 2, 3, 3, 0, 1, 3, 2, 1,\n",
              "       0, 1, 0, 3, 2, 1, 0, 3, 3, 3, 0, 3, 3, 0, 3, 2, 0, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 0, 3, 0, 2, 3, 3, 0, 3, 0, 1, 1, 3, 0, 3, 3, 0, 3, 0, 0,\n",
              "       3, 3, 2, 2, 0, 2, 2, 0, 3, 3, 3, 2, 2, 0, 0, 0, 3, 3, 2, 0, 3, 3,\n",
              "       0, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 2, 2, 0, 2, 1, 1,\n",
              "       1, 1, 0, 2, 0, 3, 0, 3, 0, 2, 1, 3, 3, 3, 3, 1, 1, 3, 1, 2, 0, 0,\n",
              "       3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 2, 3, 3, 3, 3, 3, 2, 0, 3, 3,\n",
              "       0, 1, 3, 3, 1, 1, 3, 1, 1, 3, 3, 1, 0, 3, 3, 0, 0, 1, 2, 1, 3, 1,\n",
              "       1, 3, 1, 3, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 3, 1, 3, 0, 2, 3, 2, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-edHmFAau92",
        "outputId": "896b6be9-adae-4881-8cae-ec4732682be1"
      },
      "source": [
        "dna_code.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12906, 658)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr2dt6HKWWJ_",
        "outputId": "06b65288-e013-42ca-d283-7e00ce146612"
      },
      "source": [
        "from tensorflow.python.keras.layers.core import Flatten\n",
        "y_train = pd.read_csv (r'/content/train_labels.csv')\n",
        "ytrain = np.array(y_train['labels'], dtype = \"uint32\")\n",
        "\n",
        "model = tf.keras.models.Sequential([  \n",
        "  keras.Input(shape=(658)),\n",
        "  layers.Dense(518, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1220, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(dna_code, ytrain, epochs=60, validation_split=0.3, verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "283/283 - 3s - loss: 6.9893 - accuracy: 0.0205 - val_loss: 6.8293 - val_accuracy: 0.0315\n",
            "Epoch 2/60\n",
            "283/283 - 2s - loss: 6.6242 - accuracy: 0.0513 - val_loss: 6.5268 - val_accuracy: 0.0617\n",
            "Epoch 3/60\n",
            "283/283 - 2s - loss: 6.2270 - accuracy: 0.0825 - val_loss: 6.1803 - val_accuracy: 0.0935\n",
            "Epoch 4/60\n",
            "283/283 - 2s - loss: 5.7863 - accuracy: 0.1344 - val_loss: 5.8148 - val_accuracy: 0.1405\n",
            "Epoch 5/60\n",
            "283/283 - 2s - loss: 5.2657 - accuracy: 0.2123 - val_loss: 5.3656 - val_accuracy: 0.1839\n",
            "Epoch 6/60\n",
            "283/283 - 2s - loss: 4.6554 - accuracy: 0.2991 - val_loss: 4.7652 - val_accuracy: 0.2678\n",
            "Epoch 7/60\n",
            "283/283 - 2s - loss: 3.9746 - accuracy: 0.4035 - val_loss: 4.1836 - val_accuracy: 0.3192\n",
            "Epoch 8/60\n",
            "283/283 - 2s - loss: 3.2846 - accuracy: 0.5052 - val_loss: 3.5842 - val_accuracy: 0.4029\n",
            "Epoch 9/60\n",
            "283/283 - 2s - loss: 2.6183 - accuracy: 0.6136 - val_loss: 2.9881 - val_accuracy: 0.4954\n",
            "Epoch 10/60\n",
            "283/283 - 2s - loss: 2.0348 - accuracy: 0.7054 - val_loss: 2.4390 - val_accuracy: 0.5938\n",
            "Epoch 11/60\n",
            "283/283 - 2s - loss: 1.5578 - accuracy: 0.7726 - val_loss: 2.0256 - val_accuracy: 0.6387\n",
            "Epoch 12/60\n",
            "283/283 - 2s - loss: 1.1867 - accuracy: 0.8301 - val_loss: 1.7334 - val_accuracy: 0.6852\n",
            "Epoch 13/60\n",
            "283/283 - 2s - loss: 0.9164 - accuracy: 0.8660 - val_loss: 1.3704 - val_accuracy: 0.7608\n",
            "Epoch 14/60\n",
            "283/283 - 2s - loss: 0.7228 - accuracy: 0.8932 - val_loss: 1.2059 - val_accuracy: 0.7898\n",
            "Epoch 15/60\n",
            "283/283 - 2s - loss: 0.5791 - accuracy: 0.9130 - val_loss: 0.9799 - val_accuracy: 0.8453\n",
            "Epoch 16/60\n",
            "283/283 - 2s - loss: 0.4793 - accuracy: 0.9242 - val_loss: 0.8350 - val_accuracy: 0.8773\n",
            "Epoch 17/60\n",
            "283/283 - 2s - loss: 0.3995 - accuracy: 0.9360 - val_loss: 0.7800 - val_accuracy: 0.8786\n",
            "Epoch 18/60\n",
            "283/283 - 2s - loss: 0.3435 - accuracy: 0.9434 - val_loss: 0.7175 - val_accuracy: 0.8869\n",
            "Epoch 19/60\n",
            "283/283 - 2s - loss: 0.2942 - accuracy: 0.9494 - val_loss: 0.6473 - val_accuracy: 0.9052\n",
            "Epoch 20/60\n",
            "283/283 - 2s - loss: 0.2509 - accuracy: 0.9582 - val_loss: 0.6947 - val_accuracy: 0.8877\n",
            "Epoch 21/60\n",
            "283/283 - 2s - loss: 0.2281 - accuracy: 0.9608 - val_loss: 0.6705 - val_accuracy: 0.8835\n",
            "Epoch 22/60\n",
            "283/283 - 2s - loss: 0.2008 - accuracy: 0.9652 - val_loss: 0.8680 - val_accuracy: 0.8277\n",
            "Epoch 23/60\n",
            "283/283 - 2s - loss: 0.1782 - accuracy: 0.9692 - val_loss: 0.5320 - val_accuracy: 0.9272\n",
            "Epoch 24/60\n",
            "283/283 - 2s - loss: 0.1599 - accuracy: 0.9725 - val_loss: 0.5470 - val_accuracy: 0.9233\n",
            "Epoch 25/60\n",
            "283/283 - 2s - loss: 0.1461 - accuracy: 0.9740 - val_loss: 0.5390 - val_accuracy: 0.9174\n",
            "Epoch 26/60\n",
            "283/283 - 2s - loss: 0.1317 - accuracy: 0.9768 - val_loss: 0.5073 - val_accuracy: 0.9207\n",
            "Epoch 27/60\n",
            "283/283 - 2s - loss: 0.1217 - accuracy: 0.9793 - val_loss: 0.4941 - val_accuracy: 0.9300\n",
            "Epoch 28/60\n",
            "283/283 - 2s - loss: 0.1111 - accuracy: 0.9820 - val_loss: 0.4963 - val_accuracy: 0.9313\n",
            "Epoch 29/60\n",
            "283/283 - 2s - loss: 0.0996 - accuracy: 0.9846 - val_loss: 0.4777 - val_accuracy: 0.9344\n",
            "Epoch 30/60\n",
            "283/283 - 2s - loss: 0.0905 - accuracy: 0.9857 - val_loss: 0.4906 - val_accuracy: 0.9287\n",
            "Epoch 31/60\n",
            "283/283 - 2s - loss: 0.0892 - accuracy: 0.9849 - val_loss: 0.4918 - val_accuracy: 0.9300\n",
            "Epoch 32/60\n",
            "283/283 - 2s - loss: 0.0779 - accuracy: 0.9874 - val_loss: 0.4639 - val_accuracy: 0.9323\n",
            "Epoch 33/60\n",
            "283/283 - 2s - loss: 0.0765 - accuracy: 0.9874 - val_loss: 0.5677 - val_accuracy: 0.9184\n",
            "Epoch 34/60\n",
            "283/283 - 2s - loss: 0.0721 - accuracy: 0.9874 - val_loss: 0.4519 - val_accuracy: 0.9339\n",
            "Epoch 35/60\n",
            "283/283 - 2s - loss: 0.0666 - accuracy: 0.9892 - val_loss: 0.4899 - val_accuracy: 0.9259\n",
            "Epoch 36/60\n",
            "283/283 - 2s - loss: 0.0649 - accuracy: 0.9882 - val_loss: 0.5006 - val_accuracy: 0.9261\n",
            "Epoch 37/60\n",
            "283/283 - 2s - loss: 0.0615 - accuracy: 0.9889 - val_loss: 0.4629 - val_accuracy: 0.9362\n",
            "Epoch 38/60\n",
            "283/283 - 2s - loss: 0.0582 - accuracy: 0.9900 - val_loss: 0.4495 - val_accuracy: 0.9383\n",
            "Epoch 39/60\n",
            "283/283 - 2s - loss: 0.0528 - accuracy: 0.9907 - val_loss: 0.4529 - val_accuracy: 0.9372\n",
            "Epoch 40/60\n",
            "283/283 - 2s - loss: 0.0507 - accuracy: 0.9916 - val_loss: 0.4910 - val_accuracy: 0.9318\n",
            "Epoch 41/60\n",
            "283/283 - 2s - loss: 0.0495 - accuracy: 0.9920 - val_loss: 0.4417 - val_accuracy: 0.9406\n",
            "Epoch 42/60\n",
            "283/283 - 2s - loss: 0.0477 - accuracy: 0.9910 - val_loss: 0.4467 - val_accuracy: 0.9396\n",
            "Epoch 43/60\n",
            "283/283 - 2s - loss: 0.0436 - accuracy: 0.9928 - val_loss: 0.5948 - val_accuracy: 0.9106\n",
            "Epoch 44/60\n",
            "283/283 - 2s - loss: 0.0455 - accuracy: 0.9920 - val_loss: 0.4394 - val_accuracy: 0.9409\n",
            "Epoch 45/60\n",
            "283/283 - 2s - loss: 0.0384 - accuracy: 0.9938 - val_loss: 0.4422 - val_accuracy: 0.9396\n",
            "Epoch 46/60\n",
            "283/283 - 2s - loss: 0.0381 - accuracy: 0.9939 - val_loss: 0.4418 - val_accuracy: 0.9424\n",
            "Epoch 47/60\n",
            "283/283 - 2s - loss: 0.0372 - accuracy: 0.9941 - val_loss: 0.4346 - val_accuracy: 0.9437\n",
            "Epoch 48/60\n",
            "283/283 - 2s - loss: 0.0351 - accuracy: 0.9942 - val_loss: 0.4407 - val_accuracy: 0.9416\n",
            "Epoch 49/60\n",
            "283/283 - 2s - loss: 0.0352 - accuracy: 0.9938 - val_loss: 0.4402 - val_accuracy: 0.9416\n",
            "Epoch 50/60\n",
            "283/283 - 2s - loss: 0.0354 - accuracy: 0.9946 - val_loss: 0.4358 - val_accuracy: 0.9427\n",
            "Epoch 51/60\n",
            "283/283 - 2s - loss: 0.0326 - accuracy: 0.9945 - val_loss: 0.4364 - val_accuracy: 0.9427\n",
            "Epoch 52/60\n",
            "283/283 - 2s - loss: 0.0322 - accuracy: 0.9940 - val_loss: 0.4381 - val_accuracy: 0.9419\n",
            "Epoch 53/60\n",
            "283/283 - 2s - loss: 0.0319 - accuracy: 0.9942 - val_loss: 0.4347 - val_accuracy: 0.9450\n",
            "Epoch 54/60\n",
            "283/283 - 2s - loss: 0.0307 - accuracy: 0.9946 - val_loss: 0.4401 - val_accuracy: 0.9411\n",
            "Epoch 55/60\n",
            "283/283 - 2s - loss: 0.0290 - accuracy: 0.9949 - val_loss: 0.4326 - val_accuracy: 0.9440\n",
            "Epoch 56/60\n",
            "283/283 - 2s - loss: 0.0298 - accuracy: 0.9940 - val_loss: 0.4326 - val_accuracy: 0.9429\n",
            "Epoch 57/60\n",
            "283/283 - 2s - loss: 0.0274 - accuracy: 0.9949 - val_loss: 0.4340 - val_accuracy: 0.9434\n",
            "Epoch 58/60\n",
            "283/283 - 2s - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.4682 - val_accuracy: 0.9323\n",
            "Epoch 59/60\n",
            "283/283 - 2s - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.4273 - val_accuracy: 0.9452\n",
            "Epoch 60/60\n",
            "283/283 - 2s - loss: 0.0234 - accuracy: 0.9959 - val_loss: 0.4345 - val_accuracy: 0.9442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46c7f2f250>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}