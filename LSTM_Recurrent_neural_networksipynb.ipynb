{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM/Recurrent neural networksipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eaJPokSlKnr"
      },
      "source": [
        "# LSTM/Recurrent neural networks\n",
        "\n",
        "*   Input data shape (12906, 658) with integer encoding.\n",
        "*   The training accuracy with 100 epochs can lead to 97%. The following training accuracy with 50 epochs is up to 96.82%.\n",
        "*   Training speed is the lowest among all seven methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwE977jQjxEr"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "2KwxM4l0kZlU",
        "outputId": "4299faa9-5562-4487-8e1b-ab2a386731ba"
      },
      "source": [
        "## adjust the length of DNA sequence with 658\n",
        "## remove the uncorrect characters 'K','M', 'N', 'R', 'S', 'W', 'Y'\n",
        "df = pd.read_csv (r'/content/train_features.csv')\n",
        "def equal_length(seq):\n",
        "    seq2 = seq.ljust(1058, '-') \n",
        "    fir = seq2[0:658]\n",
        "    remove_characters = ['K','M', 'N', 'R', 'S', 'W', 'Y']\n",
        "    for character in remove_characters:\n",
        "        fir = fir.replace(character, \"-\")\n",
        "    return fir\n",
        "dna = df.dna.apply(equal_length)\n",
        "## Example for arbitery DNA sequence\n",
        "dna[3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AACATTATATTTTATTTTTGGTGCATGAGCTGGAATAGTAGGAACTTCATTAAGTATGCTAATTCGAGCTGAATTAGGAAACCCAGGTGCATTAATTGGAGATGACCAAATTTATAATGTTATTGTTACTGCACATGCATTTATTATGATTTTTTTTATAGTTATACCTATTATAATTGGAGGATTTGGAAATTGATTAGTTCCTTTAATATTAGGAGCCCCAGATATAGCTTTTCCTCGAATAAATAATATAAGTTTTTGATTACTTCCTCCTTCATTAACGCTCCTCTTAATAAGAAGTCTAGTG---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEsomVTbkcMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572a7794-d0b8-44ae-bf7b-1014b61fc8b2"
      },
      "source": [
        "## Transfer Character to Int\n",
        "from numpy import argmax\n",
        "def num_encoder(seq):\n",
        "  alphabet = 'ACGT-'\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "  to_array = [char_to_int[char] for char in seq]\n",
        "  return(np.array(to_array).reshape((658)))\n",
        "\n",
        "dna_code = np.array(dna.apply(num_encoder).to_list())\n",
        "## Example\n",
        "dna_code[3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 2, 3,\n",
              "       2, 1, 0, 3, 2, 0, 2, 1, 3, 2, 2, 0, 0, 3, 0, 2, 3, 0, 2, 2, 0, 0,\n",
              "       1, 3, 3, 1, 0, 3, 3, 0, 0, 2, 3, 0, 3, 2, 1, 3, 0, 0, 3, 3, 1, 2,\n",
              "       0, 2, 1, 3, 2, 0, 0, 3, 3, 0, 2, 2, 0, 0, 0, 1, 1, 1, 0, 2, 2, 3,\n",
              "       2, 1, 0, 3, 3, 0, 0, 3, 3, 2, 2, 0, 2, 0, 3, 2, 0, 1, 1, 0, 0, 0,\n",
              "       3, 3, 3, 0, 3, 0, 0, 3, 2, 3, 3, 0, 3, 3, 2, 3, 3, 0, 1, 3, 2, 1,\n",
              "       0, 1, 0, 3, 2, 1, 0, 3, 3, 3, 0, 3, 3, 0, 3, 2, 0, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 0, 3, 0, 2, 3, 3, 0, 3, 0, 1, 1, 3, 0, 3, 3, 0, 3, 0, 0,\n",
              "       3, 3, 2, 2, 0, 2, 2, 0, 3, 3, 3, 2, 2, 0, 0, 0, 3, 3, 2, 0, 3, 3,\n",
              "       0, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 2, 2, 0, 2, 1, 1,\n",
              "       1, 1, 0, 2, 0, 3, 0, 3, 0, 2, 1, 3, 3, 3, 3, 1, 1, 3, 1, 2, 0, 0,\n",
              "       3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 2, 3, 3, 3, 3, 3, 2, 0, 3, 3,\n",
              "       0, 1, 3, 3, 1, 1, 3, 1, 1, 3, 3, 1, 0, 3, 3, 0, 0, 1, 2, 1, 3, 1,\n",
              "       1, 3, 1, 3, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 3, 1, 3, 0, 2, 3, 2, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPdE9NEmkurb"
      },
      "source": [
        "y_train = pd.read_csv (r'/content/train_labels.csv')\n",
        "ytrain = np.array(y_train['labels'], dtype = \"uint32\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQsBIY_bkdMw",
        "outputId": "e0469493-6d6b-42aa-9f79-3f8497b0bda5"
      },
      "source": [
        "model = tf.keras.models.Sequential([  \n",
        "  keras.Input(shape=(658)),\n",
        "  layers.Embedding(input_dim=658, output_dim=64),\n",
        "  #tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.LSTM(12,return_sequences=True, input_shape = (None, 658)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(1220, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(dna_code, ytrain, epochs=50, validation_split=0.3, verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "283/283 - 36s - loss: 6.0490 - accuracy: 0.1160 - val_loss: 3.6384 - val_accuracy: 0.4101\n",
            "Epoch 2/50\n",
            "283/283 - 33s - loss: 1.0415 - accuracy: 0.8058 - val_loss: 0.4855 - val_accuracy: 0.9127\n",
            "Epoch 3/50\n",
            "283/283 - 33s - loss: 0.1265 - accuracy: 0.9717 - val_loss: 0.3850 - val_accuracy: 0.9357\n",
            "Epoch 4/50\n",
            "283/283 - 33s - loss: 0.0643 - accuracy: 0.9851 - val_loss: 0.3748 - val_accuracy: 0.9445\n",
            "Epoch 5/50\n",
            "283/283 - 33s - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.3009 - val_accuracy: 0.9558\n",
            "Epoch 6/50\n",
            "283/283 - 33s - loss: 0.0416 - accuracy: 0.9903 - val_loss: 0.3015 - val_accuracy: 0.9540\n",
            "Epoch 7/50\n",
            "283/283 - 33s - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.3117 - val_accuracy: 0.9605\n",
            "Epoch 8/50\n",
            "283/283 - 33s - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.3141 - val_accuracy: 0.9602\n",
            "Epoch 9/50\n",
            "283/283 - 33s - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.3375 - val_accuracy: 0.9571\n",
            "Epoch 10/50\n",
            "283/283 - 33s - loss: 0.0781 - accuracy: 0.9775 - val_loss: 0.4219 - val_accuracy: 0.9416\n",
            "Epoch 11/50\n",
            "283/283 - 33s - loss: 0.0636 - accuracy: 0.9844 - val_loss: 0.3853 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "283/283 - 33s - loss: 0.0428 - accuracy: 0.9887 - val_loss: 0.3595 - val_accuracy: 0.9543\n",
            "Epoch 13/50\n",
            "283/283 - 33s - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.3056 - val_accuracy: 0.9607\n",
            "Epoch 14/50\n",
            "283/283 - 33s - loss: 0.0334 - accuracy: 0.9949 - val_loss: 0.2929 - val_accuracy: 0.9600\n",
            "Epoch 15/50\n",
            "283/283 - 33s - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.3153 - val_accuracy: 0.9589\n",
            "Epoch 16/50\n",
            "283/283 - 33s - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.3025 - val_accuracy: 0.9600\n",
            "Epoch 17/50\n",
            "283/283 - 33s - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.3089 - val_accuracy: 0.9620\n",
            "Epoch 18/50\n",
            "283/283 - 33s - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.3260 - val_accuracy: 0.9600\n",
            "Epoch 19/50\n",
            "283/283 - 33s - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.3138 - val_accuracy: 0.9638\n",
            "Epoch 20/50\n",
            "283/283 - 32s - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.3317 - val_accuracy: 0.9574\n",
            "Epoch 21/50\n",
            "283/283 - 33s - loss: 0.0288 - accuracy: 0.9947 - val_loss: 0.3650 - val_accuracy: 0.9520\n",
            "Epoch 22/50\n",
            "283/283 - 33s - loss: 0.0678 - accuracy: 0.9844 - val_loss: 0.3729 - val_accuracy: 0.9527\n",
            "Epoch 23/50\n",
            "283/283 - 33s - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.3633 - val_accuracy: 0.9613\n",
            "Epoch 24/50\n",
            "283/283 - 33s - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.3610 - val_accuracy: 0.9633\n",
            "Epoch 25/50\n",
            "283/283 - 33s - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.3363 - val_accuracy: 0.9638\n",
            "Epoch 26/50\n",
            "283/283 - 33s - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.3109 - val_accuracy: 0.9628\n",
            "Epoch 27/50\n",
            "283/283 - 33s - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.3051 - val_accuracy: 0.9646\n",
            "Epoch 28/50\n",
            "283/283 - 33s - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.3054 - val_accuracy: 0.9659\n",
            "Epoch 29/50\n",
            "283/283 - 33s - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.3096 - val_accuracy: 0.9649\n",
            "Epoch 30/50\n",
            "283/283 - 32s - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.3244 - val_accuracy: 0.9626\n",
            "Epoch 31/50\n",
            "283/283 - 32s - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3151 - val_accuracy: 0.9628\n",
            "Epoch 32/50\n",
            "283/283 - 32s - loss: 0.0187 - accuracy: 0.9956 - val_loss: 0.4073 - val_accuracy: 0.9491\n",
            "Epoch 33/50\n",
            "283/283 - 33s - loss: 0.0508 - accuracy: 0.9876 - val_loss: 0.4319 - val_accuracy: 0.9489\n",
            "Epoch 34/50\n",
            "283/283 - 33s - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.3996 - val_accuracy: 0.9564\n",
            "Epoch 35/50\n",
            "283/283 - 32s - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.4005 - val_accuracy: 0.9595\n",
            "Epoch 36/50\n",
            "283/283 - 32s - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.3400 - val_accuracy: 0.9657\n",
            "Epoch 37/50\n",
            "283/283 - 33s - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.3725 - val_accuracy: 0.9631\n",
            "Epoch 38/50\n",
            "283/283 - 33s - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.3153 - val_accuracy: 0.9662\n",
            "Epoch 39/50\n",
            "283/283 - 33s - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.3483 - val_accuracy: 0.9682\n",
            "Epoch 40/50\n",
            "283/283 - 33s - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.3660 - val_accuracy: 0.9628\n",
            "Epoch 41/50\n",
            "283/283 - 32s - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.3429 - val_accuracy: 0.9623\n",
            "Epoch 42/50\n",
            "283/283 - 33s - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3450 - val_accuracy: 0.9669\n",
            "Epoch 43/50\n",
            "283/283 - 32s - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3680 - val_accuracy: 0.9628\n",
            "Epoch 44/50\n",
            "283/283 - 32s - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.3621 - val_accuracy: 0.9633\n",
            "Epoch 45/50\n",
            "283/283 - 33s - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.4047 - val_accuracy: 0.9626\n",
            "Epoch 46/50\n",
            "283/283 - 32s - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.4529 - val_accuracy: 0.9502\n",
            "Epoch 47/50\n",
            "283/283 - 33s - loss: 0.0293 - accuracy: 0.9920 - val_loss: 0.4092 - val_accuracy: 0.9579\n",
            "Epoch 48/50\n",
            "283/283 - 33s - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4045 - val_accuracy: 0.9620\n",
            "Epoch 49/50\n",
            "283/283 - 33s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3883 - val_accuracy: 0.9638\n",
            "Epoch 50/50\n",
            "283/283 - 33s - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.3767 - val_accuracy: 0.9618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fde9fbed3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}