{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZipWa86hUhS"
      },
      "source": [
        "# 1D Convolutional Variational Autoencoder\n",
        "\n",
        "*   Input data shape (12906, 658) encoded with corresponding integers.\n",
        "\n",
        "*   The training accuracy with 100 epochs can lead to 97%. The following training accuracy with 60 epochs is up to 96%.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmbv-gkFU_Lp"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "smAePK6nVjKV",
        "outputId": "43252a26-f5dd-4f74-bcfe-02e399d37d7e"
      },
      "source": [
        "## adjust the length of DNA sequence with 658\n",
        "## remove the uncorrect characters 'K','M', 'N', 'R', 'S', 'W', 'Y'\n",
        "df = pd.read_csv (r'/content/train_features.csv')\n",
        "def equal_length(seq):\n",
        "    seq2 = seq.ljust(1058, '-') \n",
        "    fir = seq2[0:658]\n",
        "    remove_characters = ['K','M', 'N', 'R', 'S', 'W', 'Y']\n",
        "    for character in remove_characters:\n",
        "        fir = fir.replace(character, \"-\")\n",
        "    return fir\n",
        "dna = df.dna.apply(equal_length)\n",
        "## Example for arbitery DNA sequence\n",
        "dna[3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AACATTATATTTTATTTTTGGTGCATGAGCTGGAATAGTAGGAACTTCATTAAGTATGCTAATTCGAGCTGAATTAGGAAACCCAGGTGCATTAATTGGAGATGACCAAATTTATAATGTTATTGTTACTGCACATGCATTTATTATGATTTTTTTTATAGTTATACCTATTATAATTGGAGGATTTGGAAATTGATTAGTTCCTTTAATATTAGGAGCCCCAGATATAGCTTTTCCTCGAATAAATAATATAAGTTTTTGATTACTTCCTCCTTCATTAACGCTCCTCTTAATAAGAAGTCTAGTG---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2FkaLpyYS04",
        "outputId": "94f7f063-38bf-4720-a85e-906325db1c7b"
      },
      "source": [
        "## Transfer Character to Int\n",
        "from numpy import argmax\n",
        "def num_encoder(seq):\n",
        "  alphabet = 'ACGT-'\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "  to_array = [char_to_int[char] for char in seq]\n",
        "  return(np.array(to_array).reshape((658)))\n",
        "\n",
        "dna_code = np.array(dna.apply(num_encoder).to_list())\n",
        "## Example\n",
        "dna_code[3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 2, 3,\n",
              "       2, 1, 0, 3, 2, 0, 2, 1, 3, 2, 2, 0, 0, 3, 0, 2, 3, 0, 2, 2, 0, 0,\n",
              "       1, 3, 3, 1, 0, 3, 3, 0, 0, 2, 3, 0, 3, 2, 1, 3, 0, 0, 3, 3, 1, 2,\n",
              "       0, 2, 1, 3, 2, 0, 0, 3, 3, 0, 2, 2, 0, 0, 0, 1, 1, 1, 0, 2, 2, 3,\n",
              "       2, 1, 0, 3, 3, 0, 0, 3, 3, 2, 2, 0, 2, 0, 3, 2, 0, 1, 1, 0, 0, 0,\n",
              "       3, 3, 3, 0, 3, 0, 0, 3, 2, 3, 3, 0, 3, 3, 2, 3, 3, 0, 1, 3, 2, 1,\n",
              "       0, 1, 0, 3, 2, 1, 0, 3, 3, 3, 0, 3, 3, 0, 3, 2, 0, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 0, 3, 0, 2, 3, 3, 0, 3, 0, 1, 1, 3, 0, 3, 3, 0, 3, 0, 0,\n",
              "       3, 3, 2, 2, 0, 2, 2, 0, 3, 3, 3, 2, 2, 0, 0, 0, 3, 3, 2, 0, 3, 3,\n",
              "       0, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 2, 2, 0, 2, 1, 1,\n",
              "       1, 1, 0, 2, 0, 3, 0, 3, 0, 2, 1, 3, 3, 3, 3, 1, 1, 3, 1, 2, 0, 0,\n",
              "       3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 2, 3, 3, 3, 3, 3, 2, 0, 3, 3,\n",
              "       0, 1, 3, 3, 1, 1, 3, 1, 1, 3, 3, 1, 0, 3, 3, 0, 0, 1, 2, 1, 3, 1,\n",
              "       1, 3, 1, 3, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 3, 1, 3, 0, 2, 3, 2, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-edHmFAau92",
        "outputId": "1da77ca5-52ea-4cf7-d1fe-f3987b4898a7"
      },
      "source": [
        "dna_code.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12906, 658)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr2dt6HKWWJ_",
        "outputId": "159214e2-b32f-44b2-a0be-d378a35c9c6e"
      },
      "source": [
        "from tensorflow.python.keras.layers.core import Flatten\n",
        "y_train = pd.read_csv (r'/content/train_labels.csv')\n",
        "ytrain = np.array(y_train['labels'], dtype = \"uint32\")\n",
        "xtrain = np.expand_dims(dna_code, -1)\n",
        "model = tf.keras.models.Sequential([  \n",
        "  keras.Input(shape=(658,1)),\n",
        "  layers.Conv1D(258, 3, activation=\"relu\", padding=\"same\"),\n",
        "  layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  layers.Dense(518, activation='relu'),\n",
        "  tf.keras.layers.Dense(1220, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=60, validation_split=0.3, verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "283/283 - 8s - loss: 7.0347 - accuracy: 0.0108 - val_loss: 6.9336 - val_accuracy: 0.0207\n",
            "Epoch 2/60\n",
            "283/283 - 7s - loss: 6.6849 - accuracy: 0.0469 - val_loss: 6.5279 - val_accuracy: 0.0666\n",
            "Epoch 3/60\n",
            "283/283 - 7s - loss: 5.4314 - accuracy: 0.1843 - val_loss: 6.5272 - val_accuracy: 0.1051\n",
            "Epoch 4/60\n",
            "283/283 - 7s - loss: 2.9895 - accuracy: 0.4817 - val_loss: 6.0366 - val_accuracy: 0.1420\n",
            "Epoch 5/60\n",
            "283/283 - 7s - loss: 1.0314 - accuracy: 0.7980 - val_loss: 5.3719 - val_accuracy: 0.1116\n",
            "Epoch 6/60\n",
            "283/283 - 7s - loss: 0.7058 - accuracy: 0.8768 - val_loss: 0.6833 - val_accuracy: 0.8802\n",
            "Epoch 7/60\n",
            "283/283 - 7s - loss: 0.2301 - accuracy: 0.9489 - val_loss: 0.5855 - val_accuracy: 0.9032\n",
            "Epoch 8/60\n",
            "283/283 - 7s - loss: 0.1467 - accuracy: 0.9680 - val_loss: 0.7450 - val_accuracy: 0.8732\n",
            "Epoch 9/60\n",
            "283/283 - 7s - loss: 0.0995 - accuracy: 0.9811 - val_loss: 2.4078 - val_accuracy: 0.4533\n",
            "Epoch 10/60\n",
            "283/283 - 7s - loss: 0.3529 - accuracy: 0.9586 - val_loss: 0.4865 - val_accuracy: 0.9396\n",
            "Epoch 11/60\n",
            "283/283 - 7s - loss: 0.0715 - accuracy: 0.9878 - val_loss: 0.4104 - val_accuracy: 0.9440\n",
            "Epoch 12/60\n",
            "283/283 - 7s - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.4252 - val_accuracy: 0.9445\n",
            "Epoch 13/60\n",
            "283/283 - 7s - loss: 0.0468 - accuracy: 0.9901 - val_loss: 0.4208 - val_accuracy: 0.9509\n",
            "Epoch 14/60\n",
            "283/283 - 7s - loss: 0.0296 - accuracy: 0.9946 - val_loss: 0.4109 - val_accuracy: 0.9489\n",
            "Epoch 15/60\n",
            "283/283 - 7s - loss: 0.0323 - accuracy: 0.9934 - val_loss: 0.4028 - val_accuracy: 0.9507\n",
            "Epoch 16/60\n",
            "283/283 - 7s - loss: 0.0372 - accuracy: 0.9920 - val_loss: 0.3920 - val_accuracy: 0.9514\n",
            "Epoch 17/60\n",
            "283/283 - 7s - loss: 0.0271 - accuracy: 0.9944 - val_loss: 0.3976 - val_accuracy: 0.9514\n",
            "Epoch 18/60\n",
            "283/283 - 7s - loss: 0.0247 - accuracy: 0.9954 - val_loss: 0.3825 - val_accuracy: 0.9520\n",
            "Epoch 19/60\n",
            "283/283 - 7s - loss: 0.0262 - accuracy: 0.9944 - val_loss: 0.3764 - val_accuracy: 0.9525\n",
            "Epoch 20/60\n",
            "283/283 - 7s - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.3821 - val_accuracy: 0.9538\n",
            "Epoch 21/60\n",
            "283/283 - 7s - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.3920 - val_accuracy: 0.9527\n",
            "Epoch 22/60\n",
            "283/283 - 7s - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.3865 - val_accuracy: 0.9527\n",
            "Epoch 23/60\n",
            "283/283 - 7s - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.3815 - val_accuracy: 0.9551\n",
            "Epoch 24/60\n",
            "283/283 - 7s - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.3686 - val_accuracy: 0.9571\n",
            "Epoch 25/60\n",
            "283/283 - 7s - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.3936 - val_accuracy: 0.9545\n",
            "Epoch 26/60\n",
            "283/283 - 7s - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.3820 - val_accuracy: 0.9553\n",
            "Epoch 27/60\n",
            "283/283 - 7s - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.3737 - val_accuracy: 0.9576\n",
            "Epoch 28/60\n",
            "283/283 - 7s - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.3748 - val_accuracy: 0.9561\n",
            "Epoch 29/60\n",
            "283/283 - 7s - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.3749 - val_accuracy: 0.9579\n",
            "Epoch 30/60\n",
            "283/283 - 7s - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.3841 - val_accuracy: 0.9556\n",
            "Epoch 31/60\n",
            "283/283 - 7s - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.3769 - val_accuracy: 0.9561\n",
            "Epoch 32/60\n",
            "283/283 - 7s - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.3705 - val_accuracy: 0.9558\n",
            "Epoch 33/60\n",
            "283/283 - 7s - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.3691 - val_accuracy: 0.9576\n",
            "Epoch 34/60\n",
            "283/283 - 7s - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.3752 - val_accuracy: 0.9582\n",
            "Epoch 35/60\n",
            "283/283 - 7s - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.3752 - val_accuracy: 0.9561\n",
            "Epoch 36/60\n",
            "283/283 - 7s - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.3758 - val_accuracy: 0.9582\n",
            "Epoch 37/60\n",
            "283/283 - 7s - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.3777 - val_accuracy: 0.9579\n",
            "Epoch 38/60\n",
            "283/283 - 7s - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.3866 - val_accuracy: 0.9558\n",
            "Epoch 39/60\n",
            "283/283 - 7s - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.3882 - val_accuracy: 0.9561\n",
            "Epoch 40/60\n",
            "283/283 - 7s - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.3772 - val_accuracy: 0.9576\n",
            "Epoch 41/60\n",
            "283/283 - 7s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.3722 - val_accuracy: 0.9587\n",
            "Epoch 42/60\n",
            "283/283 - 7s - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.3876 - val_accuracy: 0.9576\n",
            "Epoch 43/60\n",
            "283/283 - 7s - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.3810 - val_accuracy: 0.9600\n",
            "Epoch 44/60\n",
            "283/283 - 7s - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.3756 - val_accuracy: 0.9584\n",
            "Epoch 45/60\n",
            "283/283 - 7s - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.3800 - val_accuracy: 0.9600\n",
            "Epoch 46/60\n",
            "283/283 - 7s - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.3771 - val_accuracy: 0.9579\n",
            "Epoch 47/60\n",
            "283/283 - 7s - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.3752 - val_accuracy: 0.9589\n",
            "Epoch 48/60\n",
            "283/283 - 7s - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.3792 - val_accuracy: 0.9582\n",
            "Epoch 49/60\n",
            "283/283 - 7s - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.3695 - val_accuracy: 0.9605\n",
            "Epoch 50/60\n",
            "283/283 - 7s - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.3859 - val_accuracy: 0.9574\n",
            "Epoch 51/60\n",
            "283/283 - 7s - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.3820 - val_accuracy: 0.9574\n",
            "Epoch 52/60\n",
            "283/283 - 7s - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.3760 - val_accuracy: 0.9579\n",
            "Epoch 53/60\n",
            "283/283 - 7s - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.3795 - val_accuracy: 0.9597\n",
            "Epoch 54/60\n",
            "283/283 - 7s - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3794 - val_accuracy: 0.9584\n",
            "Epoch 55/60\n",
            "283/283 - 7s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.3791 - val_accuracy: 0.9592\n",
            "Epoch 56/60\n",
            "283/283 - 7s - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.3800 - val_accuracy: 0.9582\n",
            "Epoch 57/60\n",
            "283/283 - 7s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.3803 - val_accuracy: 0.9597\n",
            "Epoch 58/60\n",
            "283/283 - 7s - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3939 - val_accuracy: 0.9584\n",
            "Epoch 59/60\n",
            "283/283 - 7s - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.3811 - val_accuracy: 0.9592\n",
            "Epoch 60/60\n",
            "283/283 - 7s - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3816 - val_accuracy: 0.9597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57f00f0750>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}